{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b790991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from convokit import Corpus, download\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
   "id": "8485c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/tern/.convokit/downloads/conversations-gone-awry-corpus\n"
     ]
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "8485c4cf",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))\n",
    "# df['messages'] = df['messages'].apply(lambda x: x[8:])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 3,
   "id": "09716f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 8069\n",
      "Number of Utterances: 30021\n",
      "Number of Conversations: 4188\n"
     ]
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "09716f5e",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
   "execution_count": null,
>>>>>>> origin/main
   "id": "31a88639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
   "execution_count": null,
>>>>>>> origin/main
   "id": "39d47f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_file = 'utterances.jsonl'\n",
    "\n",
    "with open(jsonl_file, 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "flat_data = json_normalize(data)\n",
    "\n",
    "# Convert flattened JSON data to DataFrame\n",
    "df = pd.DataFrame(flat_data)\n",
    "columns_to_drop = [column for column in df.columns if column != 'text']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "# Save DataFrame to CSV file\n",
    "csv_file = 'provoking_file.csv'\n",
    "df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 6,
   "id": "ee01c05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Okay, I've seen this view come up a few times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's not just black and white America though. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract reasoning is a skill that can be nurt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can we agree that genes account for about 50% ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twin studies studies suggest that about 80 per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  (Okay, I've seen this view come up a few times...\n",
       "1  It's not just black and white America though. ...\n",
       "2  Abstract reasoning is a skill that can be nurt...\n",
       "3  Can we agree that genes account for about 50% ...\n",
       "4  Twin studies studies suggest that about 80 per..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "ee01c05b",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
   "execution_count": null,
>>>>>>> origin/main
   "id": "0d2d9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun_and_numbers(text):\n",
    "    # Combine punctuation and digits\n",
    "    text = str(text)\n",
    "    to_remove = string.punctuation + string.digits\n",
    "    text = text.lower()\n",
    "    return text.translate(str.maketrans('', '', to_remove))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
   "execution_count": null,
>>>>>>> origin/main
   "id": "67a54313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
   "execution_count": null,
>>>>>>> origin/main
   "id": "65e95a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new column to the DataFrame\n",
    "def only_negatives(message):\n",
    "    result = model.predict([message])\n",
    "    if result == ['Negative']:\n",
    "        return message\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
   "execution_count": null,
>>>>>>> origin/main
   "id": "422e0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(only_negatives)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 11,
   "id": "0ed4aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42964\n",
      "                                                text\n",
      "0                                               None\n",
      "1                                               None\n",
      "2                                               None\n",
      "3                                               None\n",
      "4  Twin studies studies suggest that about 80 per...\n"
     ]
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "0ed4aa40",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "print(len(df.text))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 12,
   "id": "e6d33709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twin studies studies suggest that about 80 per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Are you kidding me?You decided to remove it af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&amp;gt;Nigeria is the economic capital of Africa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Something is confusing me about this conversat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I don't see why this is compelling.\\n\\nHow do ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "4   Twin studies studies suggest that about 80 per...\n",
       "6   Are you kidding me?You decided to remove it af...\n",
       "17  &gt;Nigeria is the economic capital of Africa,...\n",
       "20  Something is confusing me about this conversat...\n",
       "23  I don't see why this is compelling.\\n\\nHow do ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "e6d33709",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "df = df.dropna(subset=['text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 13,
   "id": "a27371a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13927"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "a27371a2",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "# make rows 0,1,2,3 etc.\n",
    "df = df.reset_index(drop=True)\n",
    "len(df.text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 14,
   "id": "cc44d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13927 entries, 0 to 13926\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    13927 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 108.9+ KB\n"
     ]
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "cc44d512",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "split_index = len(df) // 2\n",
    "output_df = df.iloc[split_index:].copy()\n",
    "input_df = df.iloc[:split_index].copy()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 15,
   "id": "fc425e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twin studies studies suggest that about 80 per...</td>\n",
       "      <td>Δ I see what you are saying with: \"In both cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you kidding me?You decided to remove it af...</td>\n",
       "      <td>&amp;gt;almost every woman I work with before a me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;gt;Nigeria is the economic capital of Africa,...</td>\n",
       "      <td>Like most blokes I get a shower and put my clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Something is confusing me about this conversat...</td>\n",
       "      <td>&amp;gt;Now, you're focusing on them, while comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't see why this is compelling.\\n\\nHow do ...</td>\n",
       "      <td>[Grooming](https://en.wikipedia.org/wiki/Child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Twin studies studies suggest that about 80 per...   \n",
       "1  Are you kidding me?You decided to remove it af...   \n",
       "2  &gt;Nigeria is the economic capital of Africa,...   \n",
       "3  Something is confusing me about this conversat...   \n",
       "4  I don't see why this is compelling.\\n\\nHow do ...   \n",
       "\n",
       "                                              output  \n",
       "0  Δ I see what you are saying with: \"In both cas...  \n",
       "1  &gt;almost every woman I work with before a me...  \n",
       "2  Like most blokes I get a shower and put my clo...  \n",
       "3  &gt;Now, you're focusing on them, while comple...  \n",
       "4  [Grooming](https://en.wikipedia.org/wiki/Child...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "fc425e6a",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "# Rename the 'text' column to 'input' in input_df and to 'output' in output_df\n",
    "output_df.rename(columns={'text': 'output'}, inplace=True)\n",
    "input_df.rename(columns={'text': 'input'}, inplace=True)\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# to remove all null values\n",
=======
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
    "output_df.reset_index(drop=True, inplace=True)\n",
    "input_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate input_df and output_df vertically\n",
    "df = pd.concat([input_df, output_df], axis=1)\n",
    "df.output.apply(remove_pun_and_numbers)\n",
    "df.input.apply(remove_pun_and_numbers)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 16,
   "id": "5e52abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6964 entries, 0 to 6963\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   6963 non-null   object\n",
      " 1   output  6964 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 108.9+ KB\n"
     ]
    }
   ],
=======
=======
>>>>>>> origin/main
   "execution_count": null,
   "id": "5e52abb5",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ce875",
   "metadata": {},
<<<<<<< HEAD
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of /Users/tern/Documents/software-programming/personal-coding-projects/angry-clone/angryGPT/distilgpt2/pytorch_model.bin: 352833716 bytes\n",
      "Size of /Users/tern/Documents/software-programming/personal-coding-projects/angry-clone/angryGPT/distilgpt2/pytorch_model.bin: 352833716 bytes\n",
      "Listing files in /Users/tern/Documents/software-programming/personal-coding-projects/angry-clone/angryGPT/distilgpt2:\n",
      "['config.json', 'merges.txt', 'pytorch_model.bin', 'vocab.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (GPT2LMHeadModel, GPT2Tokenizer, GPT2Config,\n",
    "                          DataCollatorForLanguageModeling, Trainer, TrainingArguments)\n",
    "\n",
    "def from_local_pretrained(directory):\n",
    "    config = GPT2Config.from_pretrained(os.path.join(directory, \"config.json\"))\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(directory)\n",
    "    model = GPT2LMHeadModel.from_pretrained(os.path.join(directory, \"pytorch_model.bin\"), config=config)\n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "local_distilgpt2_directory = os.path.join(\"/Users/tern/Documents/software-programming/personal-coding-projects/angry-clone/angryGPT\", \"distilgpt2\")\n",
    "\n",
    "model_path = os.path.join(local_distilgpt2_directory, \"pytorch_model.bin\")\n",
    "print(f\"Size of {model_path}: {os.path.getsize(model_path)} bytes\")\n",
    "\n",
    "file_path = \"/Users/tern/Documents/software-programming/personal-coding-projects/angry-clone/angryGPT/distilgpt2/pytorch_model.bin\"\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"Size of {file_path}: {file_size} bytes\")\n",
    "\n",
    "print(f\"Listing files in {local_distilgpt2_directory}:\")\n",
    "print(os.listdir(local_distilgpt2_directory))\n",
    "tokenizer, model = from_local_pretrained(local_distilgpt2_directory)\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "\n",
    "# Load the dataset\n",
    "eos_token = tokenizer.eos_token\n",
    "df = pd.read_csv(\"provoking_file.csv\")\n",
=======
=======
>>>>>>> origin/main
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Concatenate input and output messages, separated by a special token\n",
    "eos_token = tokenizer.eos_token\n",
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
    "df[\"text\"] = df[\"input\"] + eos_token + df[\"output\"]\n",
    "\n",
    "# Save the processed dataset as a text file\n",
    "df[\"text\"].to_csv(\"processed_dataset.txt\", index=False, header=False)\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, file_path, block_size):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.block_size = block_size\n",
    "        self.examples = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=False)[\"input_ids\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "# Create a CustomTextDataset and DataCollator\n",
    "dataset = CustomTextDataset(tokenizer=tokenizer, file_path=\"processed_dataset.txt\", block_size=128)\n",
=======
    "# Create a TextDataset and DataCollator\n",
    "dataset = TextDataset(tokenizer=tokenizer, file_path=\"processed_dataset.txt\", block_size=128)\n",
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
    "# Create a TextDataset and DataCollator\n",
    "dataset = TextDataset(tokenizer=tokenizer, file_path=\"processed_dataset.txt\", block_size=128)\n",
>>>>>>> origin/main
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"chatbot_output\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    per_device_train_batch_size=1,\n",
    "    save_steps=10_000,\n",
    "    gradient_accumulation_steps=1,\n",
=======
=======
>>>>>>> origin/main
    "    # changed device train batch size from 4 -> 1, less memory demanding\n",
    "    per_device_train_batch_size=1,\n",
    "    save_steps=10_000,\n",
    "    gradient_accumulation_steps = 1,\n",
<<<<<<< HEAD
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
>>>>>>> origin/main
    "    save_total_limit=2,\n",
    "    logging_steps=500,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
<<<<<<< HEAD
   "id": "340d8404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a41235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2face",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f437a",
=======
   "id": "faf1cfc7",
>>>>>>> f8131369733a3d63a11b62e4c3007ce684a1ec60
=======
   "id": "faf1cfc7",
>>>>>>> origin/main
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
